We present Kinesthesis 2.0 tool, in a theatre play, offering real-time vocal augmentation through processing using a gestural vocabulary developed from that of Khatakali traditional Indian theatre. In immersive theater, we delve into the interconnected pathways of expression, revealing an interplay between verbal and gestural elements. Our exploration focuses on embodiment, eliminating the perceived separation between mind and body, as actors engage in multimodal modulations to introduce a comprehensive portrayal of characters.
Kinesthesis 2.0, a gesture-controlled vocal augmentation tool developed by the authors, capture and translate these modulations, creating a dynamic interplay between auditory and visual storytelling. Using Python, Open Sound Control protocol, and Max/MSP, this tool contribute to the immersive experience by translating facial movements into predefined gestures. With MediaPipe for face and hand detection and OpenCV for webcam feed processing, it captures head movements, facial expressions, and hand gestures. The integration of a gesture detector, pitch shifter, multi-channel vocoder, reverb, multi-tap delay, and reverse delay introduces a novel approach to real-time voice controlling interfaces in music theatre.
In the immersive theater context, the integration of technology through Kinesthesis 2.0 expands the expressive vocabulary of performers, heightening voice, facial expressions, and gestures as conduits for conveying emotions and narratives. A case study inspired by Kathakali demonstrates how these tools embody and communicate specific feelings with precision. Actors, transcending traditional boundaries, engage in a multifaceted experience, exemplifying the synergy between technology and the performing arts.
